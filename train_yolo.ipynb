{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ YOLOv8 Training - Third Iteration\n",
        "**Enhanced Training with Optimized Hyperparameters**\n",
        "\n",
        "## üìä Previous Results:\n",
        "- **Training 1:** Baseline model\n",
        "- **Training 2 (Fine-tune):** Precision 0.793, Recall 0.679, mAP@0.5: 0.775\n",
        "\n",
        "## üéØ Target for Training 3:\n",
        "- **Precision:** > 0.85\n",
        "- **Recall:** > 0.75\n",
        "- **mAP@0.5:** > 0.85\n",
        "- **mAP@0.5-0.95:** > 0.60\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Ultralytics version: {YOLO.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Dataset Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset paths\n",
        "data_yaml = \"G:/Yolov8n/datasets/potholes_raw/data.yaml\"\n",
        "base_model = \"runs/detect/yolov8n-potholes-ft/weights/best.pt\"\n",
        "\n",
        "# Verify paths exist\n",
        "print(f\"Data YAML exists: {os.path.exists(data_yaml)}\")\n",
        "print(f\"Base model exists: {os.path.exists(base_model)}\")\n",
        "\n",
        "# Check dataset structure\n",
        "if os.path.exists(data_yaml):\n",
        "    with open(data_yaml, 'r') as f:\n",
        "        print(\"\\nDataset configuration:\")\n",
        "        print(f.read())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Important: Run Training First!\n",
        "\n",
        "**Before running the validation and test sections below, make sure to:**\n",
        "1. Run the training configuration cell (cell above)\n",
        "2. Run the training cell to completion\n",
        "3. Then run the validation and test cells\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Training Configuration - Third Iteration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training parameters for third iteration\n",
        "training_config = {\n",
        "    'data': data_yaml,\n",
        "    'model': base_model,  # Start from fine-tuned model\n",
        "    'epochs': 100,  # Optimal training epochs\n",
        "    'imgsz': 640,\n",
        "    'batch': 8,\n",
        "    'name': 'yolov8n-potholes-v3',\n",
        "    \n",
        "    # Optimized hyperparameters\n",
        "    'lr0': 0.005,  # Lower learning rate for fine-tuning\n",
        "    'lrf': 0.005,  # Final learning rate\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 5,  # Increased warmup\n",
        "    'warmup_momentum': 0.8,\n",
        "    'warmup_bias_lr': 0.1,\n",
        "    'patience': 20,  # Early stopping patience for optimal training\n",
        "    \n",
        "    # Enhanced data augmentation\n",
        "    'hsv_h': 0.02,  # Increased from 0.015\n",
        "    'hsv_s': 0.8,   # Increased from 0.7\n",
        "    'hsv_v': 0.5,   # Increased from 0.4\n",
        "    'degrees': 5.0, # Added rotation\n",
        "    'translate': 0.15,  # Increased from 0.1\n",
        "    'scale': 0.6,   # Increased from 0.5\n",
        "    'shear': 2.0,   # Added shear\n",
        "    'perspective': 0.1,  # Added perspective\n",
        "    'flipud': 0.0,\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 1.0,\n",
        "    'mixup': 0.1,   # Added mixup\n",
        "    \n",
        "    # Training settings\n",
        "    'save': True,\n",
        "    'save_period': 20,  # Save checkpoint every 20 epochs\n",
        "    'cache': False,  # Disable caching for memory efficiency\n",
        "    'workers': 4,   # Number of workers\n",
        "    'project': 'runs/detect',\n",
        "    'exist_ok': True,  # Overwrite existing runs\n",
        "}\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "for key, value in training_config.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Start Training - Third Iteration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = YOLO(training_config['model'])\n",
        "\n",
        "print(f\"Starting training with model: {training_config['model']}\")\n",
        "print(f\"Target epochs: {training_config['epochs']}\")\n",
        "print(f\"Learning rate: {training_config['lr0']}\")\n",
        "print(f\"Batch size: {training_config['batch']}\")\n",
        "print(f\"Image size: {training_config['imgsz']}\")\n",
        "\n",
        "# Start training\n",
        "results = model.train(\n",
        "    data=training_config['data'],\n",
        "    epochs=training_config['epochs'],\n",
        "    imgsz=training_config['imgsz'],\n",
        "    batch=training_config['batch'],\n",
        "    name=training_config['name'],\n",
        "    lr0=training_config['lr0'],\n",
        "    lrf=training_config['lrf'],\n",
        "    momentum=training_config['momentum'],\n",
        "    weight_decay=training_config['weight_decay'],\n",
        "    warmup_epochs=training_config['warmup_epochs'],\n",
        "    warmup_momentum=training_config['warmup_momentum'],\n",
        "    warmup_bias_lr=training_config['warmup_bias_lr'],\n",
        "    patience=training_config['patience'],\n",
        "    hsv_h=training_config['hsv_h'],\n",
        "    hsv_s=training_config['hsv_s'],\n",
        "    hsv_v=training_config['hsv_v'],\n",
        "    degrees=training_config['degrees'],\n",
        "    translate=training_config['translate'],\n",
        "    scale=training_config['scale'],\n",
        "    shear=training_config['shear'],\n",
        "    perspective=training_config['perspective'],\n",
        "    flipud=training_config['flipud'],\n",
        "    fliplr=training_config['fliplr'],\n",
        "    mosaic=training_config['mosaic'],\n",
        "    mixup=training_config['mixup'],\n",
        "    save=training_config['save'],\n",
        "    save_period=training_config['save_period'],\n",
        "    cache=training_config['cache'],\n",
        "    workers=training_config['workers'],\n",
        "    project=training_config['project'],\n",
        "    exist_ok=training_config['exist_ok']\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Training completed!\")\n",
        "print(f\"Results saved to: runs/detect/{training_config['name']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Model Validation & Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model for validation\n",
        "trained_model_path = f\"runs/detect/{training_config['name']}/weights/best.pt\"\n",
        "model = YOLO(trained_model_path)\n",
        "\n",
        "print(f\"Loaded trained model: {trained_model_path}\")\n",
        "print(f\"Model exists: {os.path.exists(trained_model_path)}\")\n",
        "\n",
        "# Validate the model\n",
        "print(\"\\nüîç Running validation...\")\n",
        "val_results = model.val(\n",
        "    data=training_config['data'],\n",
        "    imgsz=training_config['imgsz'],\n",
        "    batch=training_config['batch'],\n",
        "    save_json=True,\n",
        "    save_hybrid=True,\n",
        "    plots=True\n",
        ")\n",
        "\n",
        "print(\"\\nüìà Validation Results:\")\n",
        "print(f\"mAP@0.5: {val_results.box.map50:.4f}\")\n",
        "print(f\"mAP@0.5-0.95: {val_results.box.map:.4f}\")\n",
        "print(f\"Precision: {val_results.box.mp:.4f}\")\n",
        "print(f\"Recall: {val_results.box.mr:.4f}\")\n",
        "print(f\"F1-Score: {val_results.box.f1:.4f}\")\n",
        "\n",
        "# Check if targets are met\n",
        "target_precision = 0.85\n",
        "target_recall = 0.75\n",
        "target_map50 = 0.85\n",
        "target_map = 0.60\n",
        "\n",
        "print(f\"\\nüéØ Target Achievement:\")\n",
        "print(f\"Precision: {val_results.box.mp:.4f} / {target_precision} {'‚úÖ' if val_results.box.mp >= target_precision else '‚ùå'}\")\n",
        "print(f\"Recall: {val_results.box.mr:.4f} / {target_recall} {'‚úÖ' if val_results.box.mr >= target_recall else '‚ùå'}\")\n",
        "print(f\"mAP@0.5: {val_results.box.map50:.4f} / {target_map50} {'‚úÖ' if val_results.box.map50 >= target_map50 else '‚ùå'}\")\n",
        "print(f\"mAP@0.5-0.95: {val_results.box.map:.4f} / {target_map} {'‚úÖ' if val_results.box.map >= target_map else '‚ùå'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Test Dataset Inference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test dataset inference\n",
        "test_images_path = \"datasets/potholes_raw/test/images\"\n",
        "test_output_path = f\"runs/detect/{training_config['name']}-test-predict\"\n",
        "\n",
        "print(f\"üîç Running inference on test dataset...\")\n",
        "print(f\"Test images path: {test_images_path}\")\n",
        "print(f\"Output path: {test_output_path}\")\n",
        "\n",
        "# Run inference on test dataset\n",
        "test_results = model.predict(\n",
        "    source=test_images_path,\n",
        "    imgsz=training_config['imgsz'],\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True,\n",
        "    conf=0.25,  # Confidence threshold\n",
        "    iou=0.45,   # IoU threshold for NMS\n",
        "    project=\"runs/detect\",\n",
        "    name=f\"{training_config['name']}-test-predict\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Test inference completed!\")\n",
        "print(f\"Results saved to: {test_output_path}\")\n",
        "print(f\"Number of test images processed: {len(test_results)}\")\n",
        "\n",
        "# Count predictions\n",
        "total_predictions = 0\n",
        "for result in test_results:\n",
        "    if result.boxes is not None:\n",
        "        total_predictions += len(result.boxes)\n",
        "        \n",
        "print(f\"Total potholes detected: {total_predictions}\")\n",
        "print(f\"Average detections per image: {total_predictions/len(test_results):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Performance Analysis & Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance analysis and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Create performance summary\n",
        "performance_summary = {\n",
        "    'Metric': ['Precision', 'Recall', 'F1-Score', 'mAP@0.5', 'mAP@0.5-0.95'],\n",
        "    'Value': [\n",
        "        val_results.box.mp,\n",
        "        val_results.box.mr, \n",
        "        val_results.box.f1,\n",
        "        val_results.box.map50,\n",
        "        val_results.box.map\n",
        "    ],\n",
        "    'Target': [0.85, 0.75, 0.80, 0.85, 0.60],\n",
        "    'Achieved': [\n",
        "        '‚úÖ' if val_results.box.mp >= 0.85 else '‚ùå',\n",
        "        '‚úÖ' if val_results.box.mr >= 0.75 else '‚ùå', \n",
        "        '‚úÖ' if val_results.box.f1 >= 0.80 else '‚ùå',\n",
        "        '‚úÖ' if val_results.box.map50 >= 0.85 else '‚ùå',\n",
        "        '‚úÖ' if val_results.box.map >= 0.60 else '‚ùå'\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"üìä Performance Summary:\")\n",
        "print(\"=\" * 60)\n",
        "for i, metric in enumerate(performance_summary['Metric']):\n",
        "    print(f\"{metric:12} | {performance_summary['Value'][i]:.4f} | Target: {performance_summary['Target'][i]:.2f} | {performance_summary['Achieved'][i]}\")\n",
        "\n",
        "# Create visualization\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Bar chart of metrics\n",
        "metrics = performance_summary['Metric']\n",
        "values = performance_summary['Value']\n",
        "targets = performance_summary['Target']\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "ax1.bar(x - width/2, values, width, label='Achieved', alpha=0.8, color='skyblue')\n",
        "ax1.bar(x + width/2, targets, width, label='Target', alpha=0.8, color='lightcoral')\n",
        "\n",
        "ax1.set_xlabel('Metrics')\n",
        "ax1.set_ylabel('Score')\n",
        "ax1.set_title('Model Performance vs Targets')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(metrics, rotation=45)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (v, t) in enumerate(zip(values, targets)):\n",
        "    ax1.text(i - width/2, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
        "    ax1.text(i + width/2, t + 0.01, f'{t:.3f}', ha='center', va='bottom')\n",
        "\n",
        "# Pie chart of achievement\n",
        "achieved_count = sum(1 for status in performance_summary['Achieved'] if status == '‚úÖ')\n",
        "total_count = len(performance_summary['Achieved'])\n",
        "not_achieved_count = total_count - achieved_count\n",
        "\n",
        "ax2.pie([achieved_count, not_achieved_count], \n",
        "        labels=[f'Achieved ({achieved_count})', f'Not Achieved ({not_achieved_count})'],\n",
        "        colors=['lightgreen', 'lightcoral'],\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=90)\n",
        "ax2.set_title('Target Achievement Status')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save performance report\n",
        "report_path = f\"runs/detect/{training_config['name']}/performance_report.txt\"\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"YOLOv8 Pothole Detection - Performance Report\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "    f.write(f\"Model: {training_config['name']}\\n\")\n",
        "    f.write(f\"Training Epochs: {training_config['epochs']}\\n\")\n",
        "    f.write(f\"Learning Rate: {training_config['lr0']}\\n\")\n",
        "    f.write(f\"Batch Size: {training_config['batch']}\\n\")\n",
        "    f.write(f\"Image Size: {training_config['imgsz']}\\n\\n\")\n",
        "    \n",
        "    f.write(\"Performance Metrics:\\n\")\n",
        "    f.write(\"-\" * 30 + \"\\n\")\n",
        "    for i, metric in enumerate(performance_summary['Metric']):\n",
        "        f.write(f\"{metric}: {performance_summary['Value'][i]:.4f} (Target: {performance_summary['Target'][i]:.2f}) {performance_summary['Achieved'][i]}\\n\")\n",
        "    \n",
        "    f.write(f\"\\nTest Dataset Results:\\n\")\n",
        "    f.write(f\"Total images processed: {len(test_results)}\\n\")\n",
        "    f.write(f\"Total potholes detected: {total_predictions}\\n\")\n",
        "    f.write(f\"Average detections per image: {total_predictions/len(test_results):.2f}\\n\")\n",
        "\n",
        "print(f\"\\nüìÑ Performance report saved to: {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé• Video Inference Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Video inference test\n",
        "video_path = \"datasets/potholes_video/pothole_video.mp4\"\n",
        "video_output_path = f\"runs/detect/{training_config['name']}-video-predict\"\n",
        "\n",
        "if os.path.exists(video_path):\n",
        "    print(f\"üé• Running inference on video: {video_path}\")\n",
        "    \n",
        "    # Run inference on video\n",
        "    video_results = model.predict(\n",
        "        source=video_path,\n",
        "        imgsz=training_config['imgsz'],\n",
        "        save=True,\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        conf=0.25,\n",
        "        iou=0.45,\n",
        "        project=\"runs/detect\",\n",
        "        name=f\"{training_config['name']}-video-predict\",\n",
        "        exist_ok=True\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Video inference completed!\")\n",
        "    print(f\"Output video saved to: {video_output_path}\")\n",
        "    \n",
        "    # Get video info\n",
        "    import cv2\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = frame_count / fps\n",
        "    cap.release()\n",
        "    \n",
        "    print(f\"Video info:\")\n",
        "    print(f\"  - FPS: {fps:.2f}\")\n",
        "    print(f\"  - Total frames: {frame_count}\")\n",
        "    print(f\"  - Duration: {duration:.2f} seconds\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Video file not found: {video_path}\")\n",
        "    print(\"Skipping video inference test...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Summary & Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"üéØ YOLOv8 Training & Testing Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\nüìä Model Performance:\")\n",
        "print(f\"  ‚Ä¢ Precision: {val_results.box.mp:.4f}\")\n",
        "print(f\"  ‚Ä¢ Recall: {val_results.box.mr:.4f}\")\n",
        "print(f\"  ‚Ä¢ F1-Score: {val_results.box.f1:.4f}\")\n",
        "print(f\"  ‚Ä¢ mAP@0.5: {val_results.box.map50:.4f}\")\n",
        "print(f\"  ‚Ä¢ mAP@0.5-0.95: {val_results.box.map:.4f}\")\n",
        "\n",
        "print(f\"\\nüìÅ Output Files:\")\n",
        "print(f\"  ‚Ä¢ Model weights: runs/detect/{training_config['name']}/weights/\")\n",
        "print(f\"  ‚Ä¢ Validation plots: runs/detect/{training_config['name']}/\")\n",
        "print(f\"  ‚Ä¢ Test predictions: runs/detect/{training_config['name']}-test-predict/\")\n",
        "if os.path.exists(video_path):\n",
        "    print(f\"  ‚Ä¢ Video predictions: runs/detect/{training_config['name']}-video-predict/\")\n",
        "print(f\"  ‚Ä¢ Performance report: runs/detect/{training_config['name']}/performance_report.txt\")\n",
        "\n",
        "print(f\"\\nüîç Test Results:\")\n",
        "print(f\"  ‚Ä¢ Test images processed: {len(test_results)}\")\n",
        "print(f\"  ‚Ä¢ Total potholes detected: {total_predictions}\")\n",
        "print(f\"  ‚Ä¢ Average detections per image: {total_predictions/len(test_results):.2f}\")\n",
        "\n",
        "# Check if all targets achieved\n",
        "all_targets_met = all(status == '‚úÖ' for status in performance_summary['Achieved'])\n",
        "print(f\"\\nüéØ Target Achievement: {'‚úÖ ALL TARGETS MET!' if all_targets_met else '‚ùå Some targets not met'}\")\n",
        "print(f\"  ‚Ä¢ Targets achieved: {sum(1 for status in performance_summary['Achieved'] if status == '‚úÖ')}/{len(performance_summary['Achieved'])}\")\n",
        "\n",
        "print(f\"\\nüìà Next Steps:\")\n",
        "if not all_targets_met:\n",
        "    print(\"  ‚Ä¢ Consider adjusting hyperparameters\")\n",
        "    print(\"  ‚Ä¢ Try different data augmentation strategies\")\n",
        "    print(\"  ‚Ä¢ Increase training epochs if needed\")\n",
        "    print(\"  ‚Ä¢ Consider model architecture modifications\")\n",
        "else:\n",
        "    print(\"  ‚Ä¢ Model is ready for deployment!\")\n",
        "    print(\"  ‚Ä¢ Consider real-world testing\")\n",
        "    print(\"  ‚Ä¢ Optimize inference speed if needed\")\n",
        "\n",
        "print(f\"\\n‚úÖ Training and testing pipeline completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
